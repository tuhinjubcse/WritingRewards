{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lamp-gem-1p5-flash-s-a', 'lamp-gem-1p5-flash-p-c', 'lamp-gem-1p5-flash-p-b', 'gpt-4o-2024-08-06', 'lamp-gem-1p5-flash-ps-b', 'lamp-gem-1p5-flash-ps-a', 'lamp-gem-1p5-flash-p-e', 'lamp-gem-1p5-flash-p-a', 'lamp-gem-1p5-flash-p-d', 'llama_3.2_1b_results_constant', 'gpt-4o-mini', 'llama_3.2_1b_results_cosine', 'lamp-gem-1p5-flash-s-b', 'gemini-1.5-flash', 'lamp-4o-p', 'lamp-4o-mini-p', 'llama_3.2_1b_results_parallel']\n",
      "----------------------------data/lamp_PRGS_test.json----------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairwise</th>\n",
       "      <th>pairwise-P1</th>\n",
       "      <th>pairwise-P2</th>\n",
       "      <th>pairwise-P3</th>\n",
       "      <th>pairwise-P4</th>\n",
       "      <th>pairwise-P5</th>\n",
       "      <th>pairwise-P6</th>\n",
       "      <th>pairwise-P7</th>\n",
       "      <th>pairwise-gold</th>\n",
       "      <th>pairwise-silver</th>\n",
       "      <th>reward_MAE_R</th>\n",
       "      <th>reward_Corr_R</th>\n",
       "      <th>reward_Avg_R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lamp-4o-p</th>\n",
       "      <td>100.00</td>\n",
       "      <td>92.09</td>\n",
       "      <td>96.74</td>\n",
       "      <td>98.56</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.28</td>\n",
       "      <td>73.55</td>\n",
       "      <td>99.82</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-ps-b</th>\n",
       "      <td>100.00</td>\n",
       "      <td>87.44</td>\n",
       "      <td>96.74</td>\n",
       "      <td>98.09</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.45</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>73.96</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-ps-a</th>\n",
       "      <td>100.00</td>\n",
       "      <td>84.65</td>\n",
       "      <td>95.81</td>\n",
       "      <td>98.56</td>\n",
       "      <td>99.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>73.88</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-4o-mini-p</th>\n",
       "      <td>99.01</td>\n",
       "      <td>88.84</td>\n",
       "      <td>93.49</td>\n",
       "      <td>95.69</td>\n",
       "      <td>97.99</td>\n",
       "      <td>98.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.28</td>\n",
       "      <td>72.72</td>\n",
       "      <td>99.91</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_parallel</th>\n",
       "      <td>92.57</td>\n",
       "      <td>77.21</td>\n",
       "      <td>76.28</td>\n",
       "      <td>80.86</td>\n",
       "      <td>80.90</td>\n",
       "      <td>90.16</td>\n",
       "      <td>91.19</td>\n",
       "      <td>93.48</td>\n",
       "      <td>69.15</td>\n",
       "      <td>98.39</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_cosine</th>\n",
       "      <td>89.60</td>\n",
       "      <td>71.63</td>\n",
       "      <td>76.28</td>\n",
       "      <td>77.99</td>\n",
       "      <td>78.89</td>\n",
       "      <td>84.70</td>\n",
       "      <td>93.08</td>\n",
       "      <td>86.96</td>\n",
       "      <td>69.98</td>\n",
       "      <td>98.75</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_constant</th>\n",
       "      <td>86.14</td>\n",
       "      <td>70.70</td>\n",
       "      <td>77.21</td>\n",
       "      <td>75.12</td>\n",
       "      <td>76.38</td>\n",
       "      <td>81.42</td>\n",
       "      <td>84.28</td>\n",
       "      <td>82.61</td>\n",
       "      <td>65.34</td>\n",
       "      <td>95.71</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-s-a</th>\n",
       "      <td>80.20</td>\n",
       "      <td>55.35</td>\n",
       "      <td>57.21</td>\n",
       "      <td>63.16</td>\n",
       "      <td>63.32</td>\n",
       "      <td>71.04</td>\n",
       "      <td>69.81</td>\n",
       "      <td>73.91</td>\n",
       "      <td>66.09</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-s-b</th>\n",
       "      <td>79.46</td>\n",
       "      <td>53.02</td>\n",
       "      <td>54.88</td>\n",
       "      <td>66.51</td>\n",
       "      <td>64.82</td>\n",
       "      <td>68.85</td>\n",
       "      <td>71.07</td>\n",
       "      <td>72.46</td>\n",
       "      <td>65.34</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-c</th>\n",
       "      <td>55.20</td>\n",
       "      <td>52.56</td>\n",
       "      <td>50.23</td>\n",
       "      <td>62.68</td>\n",
       "      <td>51.76</td>\n",
       "      <td>50.27</td>\n",
       "      <td>42.14</td>\n",
       "      <td>47.10</td>\n",
       "      <td>49.17</td>\n",
       "      <td>52.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-a</th>\n",
       "      <td>50.25</td>\n",
       "      <td>52.09</td>\n",
       "      <td>49.77</td>\n",
       "      <td>52.15</td>\n",
       "      <td>51.76</td>\n",
       "      <td>43.72</td>\n",
       "      <td>47.80</td>\n",
       "      <td>53.62</td>\n",
       "      <td>50.41</td>\n",
       "      <td>49.11</td>\n",
       "      <td>2.55</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-e</th>\n",
       "      <td>50.00</td>\n",
       "      <td>51.16</td>\n",
       "      <td>52.56</td>\n",
       "      <td>49.28</td>\n",
       "      <td>47.74</td>\n",
       "      <td>46.45</td>\n",
       "      <td>53.46</td>\n",
       "      <td>49.28</td>\n",
       "      <td>48.51</td>\n",
       "      <td>49.55</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-b</th>\n",
       "      <td>47.03</td>\n",
       "      <td>50.23</td>\n",
       "      <td>54.88</td>\n",
       "      <td>49.28</td>\n",
       "      <td>51.76</td>\n",
       "      <td>41.53</td>\n",
       "      <td>52.20</td>\n",
       "      <td>47.83</td>\n",
       "      <td>50.58</td>\n",
       "      <td>51.96</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-d</th>\n",
       "      <td>47.03</td>\n",
       "      <td>46.51</td>\n",
       "      <td>44.19</td>\n",
       "      <td>45.45</td>\n",
       "      <td>49.25</td>\n",
       "      <td>45.36</td>\n",
       "      <td>48.43</td>\n",
       "      <td>52.17</td>\n",
       "      <td>49.59</td>\n",
       "      <td>51.96</td>\n",
       "      <td>2.49</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-flash</th>\n",
       "      <td>22.77</td>\n",
       "      <td>26.05</td>\n",
       "      <td>28.37</td>\n",
       "      <td>20.57</td>\n",
       "      <td>18.09</td>\n",
       "      <td>20.77</td>\n",
       "      <td>18.87</td>\n",
       "      <td>18.84</td>\n",
       "      <td>38.56</td>\n",
       "      <td>16.88</td>\n",
       "      <td>3.88</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <td>17.82</td>\n",
       "      <td>23.72</td>\n",
       "      <td>21.86</td>\n",
       "      <td>15.31</td>\n",
       "      <td>14.57</td>\n",
       "      <td>13.66</td>\n",
       "      <td>15.72</td>\n",
       "      <td>10.14</td>\n",
       "      <td>37.98</td>\n",
       "      <td>6.88</td>\n",
       "      <td>3.50</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>13.12</td>\n",
       "      <td>31.63</td>\n",
       "      <td>19.53</td>\n",
       "      <td>12.92</td>\n",
       "      <td>10.55</td>\n",
       "      <td>9.84</td>\n",
       "      <td>5.03</td>\n",
       "      <td>7.25</td>\n",
       "      <td>34.25</td>\n",
       "      <td>4.29</td>\n",
       "      <td>3.49</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pairwise  pairwise-P1  pairwise-P2  \\\n",
       "model                                                               \n",
       "lamp-4o-p                        100.00        92.09        96.74   \n",
       "lamp-gem-1p5-flash-ps-b          100.00        87.44        96.74   \n",
       "lamp-gem-1p5-flash-ps-a          100.00        84.65        95.81   \n",
       "lamp-4o-mini-p                    99.01        88.84        93.49   \n",
       "llama_3.2_1b_results_parallel     92.57        77.21        76.28   \n",
       "llama_3.2_1b_results_cosine       89.60        71.63        76.28   \n",
       "llama_3.2_1b_results_constant     86.14        70.70        77.21   \n",
       "lamp-gem-1p5-flash-s-a            80.20        55.35        57.21   \n",
       "lamp-gem-1p5-flash-s-b            79.46        53.02        54.88   \n",
       "lamp-gem-1p5-flash-p-c            55.20        52.56        50.23   \n",
       "lamp-gem-1p5-flash-p-a            50.25        52.09        49.77   \n",
       "lamp-gem-1p5-flash-p-e            50.00        51.16        52.56   \n",
       "lamp-gem-1p5-flash-p-b            47.03        50.23        54.88   \n",
       "lamp-gem-1p5-flash-p-d            47.03        46.51        44.19   \n",
       "gemini-1.5-flash                  22.77        26.05        28.37   \n",
       "gpt-4o-2024-08-06                 17.82        23.72        21.86   \n",
       "gpt-4o-mini                       13.12        31.63        19.53   \n",
       "\n",
       "                               pairwise-P3  pairwise-P4  pairwise-P5  \\\n",
       "model                                                                  \n",
       "lamp-4o-p                            98.56       100.00       100.00   \n",
       "lamp-gem-1p5-flash-ps-b              98.09        99.50        99.45   \n",
       "lamp-gem-1p5-flash-ps-a              98.56        99.50       100.00   \n",
       "lamp-4o-mini-p                       95.69        97.99        98.91   \n",
       "llama_3.2_1b_results_parallel        80.86        80.90        90.16   \n",
       "llama_3.2_1b_results_cosine          77.99        78.89        84.70   \n",
       "llama_3.2_1b_results_constant        75.12        76.38        81.42   \n",
       "lamp-gem-1p5-flash-s-a               63.16        63.32        71.04   \n",
       "lamp-gem-1p5-flash-s-b               66.51        64.82        68.85   \n",
       "lamp-gem-1p5-flash-p-c               62.68        51.76        50.27   \n",
       "lamp-gem-1p5-flash-p-a               52.15        51.76        43.72   \n",
       "lamp-gem-1p5-flash-p-e               49.28        47.74        46.45   \n",
       "lamp-gem-1p5-flash-p-b               49.28        51.76        41.53   \n",
       "lamp-gem-1p5-flash-p-d               45.45        49.25        45.36   \n",
       "gemini-1.5-flash                     20.57        18.09        20.77   \n",
       "gpt-4o-2024-08-06                    15.31        14.57        13.66   \n",
       "gpt-4o-mini                          12.92        10.55         9.84   \n",
       "\n",
       "                               pairwise-P6  pairwise-P7  pairwise-gold  \\\n",
       "model                                                                    \n",
       "lamp-4o-p                           100.00        99.28          73.55   \n",
       "lamp-gem-1p5-flash-ps-b             100.00       100.00          73.96   \n",
       "lamp-gem-1p5-flash-ps-a             100.00       100.00          73.88   \n",
       "lamp-4o-mini-p                      100.00        99.28          72.72   \n",
       "llama_3.2_1b_results_parallel        91.19        93.48          69.15   \n",
       "llama_3.2_1b_results_cosine          93.08        86.96          69.98   \n",
       "llama_3.2_1b_results_constant        84.28        82.61          65.34   \n",
       "lamp-gem-1p5-flash-s-a               69.81        73.91          66.09   \n",
       "lamp-gem-1p5-flash-s-b               71.07        72.46          65.34   \n",
       "lamp-gem-1p5-flash-p-c               42.14        47.10          49.17   \n",
       "lamp-gem-1p5-flash-p-a               47.80        53.62          50.41   \n",
       "lamp-gem-1p5-flash-p-e               53.46        49.28          48.51   \n",
       "lamp-gem-1p5-flash-p-b               52.20        47.83          50.58   \n",
       "lamp-gem-1p5-flash-p-d               48.43        52.17          49.59   \n",
       "gemini-1.5-flash                     18.87        18.84          38.56   \n",
       "gpt-4o-2024-08-06                    15.72        10.14          37.98   \n",
       "gpt-4o-mini                           5.03         7.25          34.25   \n",
       "\n",
       "                               pairwise-silver  reward_MAE_R  reward_Corr_R  \\\n",
       "model                                                                         \n",
       "lamp-4o-p                                99.82          1.50           0.38   \n",
       "lamp-gem-1p5-flash-ps-b                 100.00          2.01           0.40   \n",
       "lamp-gem-1p5-flash-ps-a                 100.00          2.80           0.43   \n",
       "lamp-4o-mini-p                           99.91          3.27           0.28   \n",
       "llama_3.2_1b_results_parallel            98.39          1.34           0.43   \n",
       "llama_3.2_1b_results_cosine              98.75          1.40           0.42   \n",
       "llama_3.2_1b_results_constant            95.71          1.38           0.37   \n",
       "lamp-gem-1p5-flash-s-a                  100.00          3.17           0.19   \n",
       "lamp-gem-1p5-flash-s-b                  100.00          3.21           0.16   \n",
       "lamp-gem-1p5-flash-p-c                   52.50          2.57          -0.06   \n",
       "lamp-gem-1p5-flash-p-a                   49.11          2.55          -0.02   \n",
       "lamp-gem-1p5-flash-p-e                   49.55          2.53          -0.07   \n",
       "lamp-gem-1p5-flash-p-b                   51.96          2.47          -0.07   \n",
       "lamp-gem-1p5-flash-p-d                   51.96          2.49          -0.06   \n",
       "gemini-1.5-flash                         16.88          3.88          -0.19   \n",
       "gpt-4o-2024-08-06                         6.88          3.50          -0.05   \n",
       "gpt-4o-mini                               4.29          3.49          -0.11   \n",
       "\n",
       "                               reward_Avg_R  \n",
       "model                                        \n",
       "lamp-4o-p                              5.74  \n",
       "lamp-gem-1p5-flash-ps-b                5.78  \n",
       "lamp-gem-1p5-flash-ps-a                7.54  \n",
       "lamp-4o-mini-p                         2.51  \n",
       "llama_3.2_1b_results_parallel          5.05  \n",
       "llama_3.2_1b_results_cosine            5.27  \n",
       "llama_3.2_1b_results_constant          4.89  \n",
       "lamp-gem-1p5-flash-s-a                 8.09  \n",
       "lamp-gem-1p5-flash-s-b                 8.14  \n",
       "lamp-gem-1p5-flash-p-c                 7.41  \n",
       "lamp-gem-1p5-flash-p-a                 7.36  \n",
       "lamp-gem-1p5-flash-p-e                 7.30  \n",
       "lamp-gem-1p5-flash-p-b                 7.22  \n",
       "lamp-gem-1p5-flash-p-d                 7.26  \n",
       "gemini-1.5-flash                       8.83  \n",
       "gpt-4o-2024-08-06                      8.45  \n",
       "gpt-4o-mini                            8.44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairwise</th>\n",
       "      <th>pairwise-P1</th>\n",
       "      <th>pairwise-P2</th>\n",
       "      <th>pairwise-P3</th>\n",
       "      <th>pairwise-P4</th>\n",
       "      <th>pairwise-P5</th>\n",
       "      <th>pairwise-P6</th>\n",
       "      <th>pairwise-P7</th>\n",
       "      <th>pairwise-gold</th>\n",
       "      <th>pairwise-silver</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-s-a</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-c</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-b</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-ps-b</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-ps-a</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-e</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-a</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-p-d</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_constant</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_cosine</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-gem-1p5-flash-s-b</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-flash</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-4o-p</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-4o-mini-p</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3.2_1b_results_parallel</th>\n",
       "      <td>404</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>209</td>\n",
       "      <td>199</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>138</td>\n",
       "      <td>1206</td>\n",
       "      <td>1120</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pairwise  pairwise-P1  pairwise-P2  \\\n",
       "model                                                               \n",
       "Total                               404          215          215   \n",
       "lamp-gem-1p5-flash-s-a              404          215          215   \n",
       "lamp-gem-1p5-flash-p-c              404          215          215   \n",
       "lamp-gem-1p5-flash-p-b              404          215          215   \n",
       "gpt-4o-2024-08-06                   404          215          215   \n",
       "lamp-gem-1p5-flash-ps-b             404          215          215   \n",
       "lamp-gem-1p5-flash-ps-a             404          215          215   \n",
       "lamp-gem-1p5-flash-p-e              404          215          215   \n",
       "lamp-gem-1p5-flash-p-a              404          215          215   \n",
       "lamp-gem-1p5-flash-p-d              404          215          215   \n",
       "llama_3.2_1b_results_constant       404          215          215   \n",
       "gpt-4o-mini                         404          215          215   \n",
       "llama_3.2_1b_results_cosine         404          215          215   \n",
       "lamp-gem-1p5-flash-s-b              404          215          215   \n",
       "gemini-1.5-flash                    404          215          215   \n",
       "lamp-4o-p                           404          215          215   \n",
       "lamp-4o-mini-p                      404          215          215   \n",
       "llama_3.2_1b_results_parallel       404          215          215   \n",
       "\n",
       "                               pairwise-P3  pairwise-P4  pairwise-P5  \\\n",
       "model                                                                  \n",
       "Total                                  209          199          183   \n",
       "lamp-gem-1p5-flash-s-a                 209          199          183   \n",
       "lamp-gem-1p5-flash-p-c                 209          199          183   \n",
       "lamp-gem-1p5-flash-p-b                 209          199          183   \n",
       "gpt-4o-2024-08-06                      209          199          183   \n",
       "lamp-gem-1p5-flash-ps-b                209          199          183   \n",
       "lamp-gem-1p5-flash-ps-a                209          199          183   \n",
       "lamp-gem-1p5-flash-p-e                 209          199          183   \n",
       "lamp-gem-1p5-flash-p-a                 209          199          183   \n",
       "lamp-gem-1p5-flash-p-d                 209          199          183   \n",
       "llama_3.2_1b_results_constant          209          199          183   \n",
       "gpt-4o-mini                            209          199          183   \n",
       "llama_3.2_1b_results_cosine            209          199          183   \n",
       "lamp-gem-1p5-flash-s-b                 209          199          183   \n",
       "gemini-1.5-flash                       209          199          183   \n",
       "lamp-4o-p                              209          199          183   \n",
       "lamp-4o-mini-p                         209          199          183   \n",
       "llama_3.2_1b_results_parallel          209          199          183   \n",
       "\n",
       "                               pairwise-P6  pairwise-P7  pairwise-gold  \\\n",
       "model                                                                    \n",
       "Total                                  159          138           1206   \n",
       "lamp-gem-1p5-flash-s-a                 159          138           1206   \n",
       "lamp-gem-1p5-flash-p-c                 159          138           1206   \n",
       "lamp-gem-1p5-flash-p-b                 159          138           1206   \n",
       "gpt-4o-2024-08-06                      159          138           1206   \n",
       "lamp-gem-1p5-flash-ps-b                159          138           1206   \n",
       "lamp-gem-1p5-flash-ps-a                159          138           1206   \n",
       "lamp-gem-1p5-flash-p-e                 159          138           1206   \n",
       "lamp-gem-1p5-flash-p-a                 159          138           1206   \n",
       "lamp-gem-1p5-flash-p-d                 159          138           1206   \n",
       "llama_3.2_1b_results_constant          159          138           1206   \n",
       "gpt-4o-mini                            159          138           1206   \n",
       "llama_3.2_1b_results_cosine            159          138           1206   \n",
       "lamp-gem-1p5-flash-s-b                 159          138           1206   \n",
       "gemini-1.5-flash                       159          138           1206   \n",
       "lamp-4o-p                              159          138           1206   \n",
       "lamp-4o-mini-p                         159          138           1206   \n",
       "llama_3.2_1b_results_parallel          159          138           1206   \n",
       "\n",
       "                               pairwise-silver  reward  \n",
       "model                                                   \n",
       "Total                                     1120     430  \n",
       "lamp-gem-1p5-flash-s-a                    1120     430  \n",
       "lamp-gem-1p5-flash-p-c                    1120     430  \n",
       "lamp-gem-1p5-flash-p-b                    1120     430  \n",
       "gpt-4o-2024-08-06                         1120     430  \n",
       "lamp-gem-1p5-flash-ps-b                   1120     430  \n",
       "lamp-gem-1p5-flash-ps-a                   1120     430  \n",
       "lamp-gem-1p5-flash-p-e                    1120     430  \n",
       "lamp-gem-1p5-flash-p-a                    1120     430  \n",
       "lamp-gem-1p5-flash-p-d                    1120     430  \n",
       "llama_3.2_1b_results_constant             1120     430  \n",
       "gpt-4o-mini                               1120     430  \n",
       "llama_3.2_1b_results_cosine               1120     430  \n",
       "lamp-gem-1p5-flash-s-b                    1120     430  \n",
       "gemini-1.5-flash                          1120     430  \n",
       "lamp-4o-p                                 1120     430  \n",
       "lamp-4o-mini-p                            1120     430  \n",
       "llama_3.2_1b_results_parallel             1120     430  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini-2024-07-18', 'lamp-4o-mini-p-editor']\n",
      "-------------------------data/lamp_PR_editor_test.json--------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairwise</th>\n",
       "      <th>pairwise-P1</th>\n",
       "      <th>pairwise-P2</th>\n",
       "      <th>pairwise-P3</th>\n",
       "      <th>pairwise-P4</th>\n",
       "      <th>pairwise-P5</th>\n",
       "      <th>pairwise-P6</th>\n",
       "      <th>pairwise-P7</th>\n",
       "      <th>reward_MAE_R</th>\n",
       "      <th>reward_Corr_R</th>\n",
       "      <th>reward_Avg_R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lamp-4o-mini-p-editor</th>\n",
       "      <td>98.64</td>\n",
       "      <td>84.47</td>\n",
       "      <td>92.83</td>\n",
       "      <td>97.16</td>\n",
       "      <td>98.80</td>\n",
       "      <td>98.83</td>\n",
       "      <td>99.60</td>\n",
       "      <td>99.46</td>\n",
       "      <td>3.61</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-2024-07-18</th>\n",
       "      <td>9.43</td>\n",
       "      <td>32.62</td>\n",
       "      <td>18.44</td>\n",
       "      <td>11.60</td>\n",
       "      <td>6.01</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.26</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>8.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pairwise  pairwise-P1  pairwise-P2  pairwise-P3  \\\n",
       "model                                                                     \n",
       "lamp-4o-mini-p-editor      98.64        84.47        92.83        97.16   \n",
       "gpt-4o-mini-2024-07-18      9.43        32.62        18.44        11.60   \n",
       "\n",
       "                        pairwise-P4  pairwise-P5  pairwise-P6  pairwise-P7  \\\n",
       "model                                                                        \n",
       "lamp-4o-mini-p-editor         98.80        98.83        99.60        99.46   \n",
       "gpt-4o-mini-2024-07-18         6.01         4.69         4.38         3.76   \n",
       "\n",
       "                        reward_MAE_R  reward_Corr_R  reward_Avg_R  \n",
       "model                                                              \n",
       "lamp-4o-mini-p-editor           3.61          -0.42          3.90  \n",
       "gpt-4o-mini-2024-07-18          3.26          -0.07          8.48  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairwise</th>\n",
       "      <th>pairwise-P1</th>\n",
       "      <th>pairwise-P2</th>\n",
       "      <th>pairwise-P3</th>\n",
       "      <th>pairwise-P4</th>\n",
       "      <th>pairwise-P5</th>\n",
       "      <th>pairwise-P6</th>\n",
       "      <th>pairwise-P7</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>880</td>\n",
       "      <td>515</td>\n",
       "      <td>488</td>\n",
       "      <td>457</td>\n",
       "      <td>416</td>\n",
       "      <td>341</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-2024-07-18</th>\n",
       "      <td>880</td>\n",
       "      <td>515</td>\n",
       "      <td>488</td>\n",
       "      <td>457</td>\n",
       "      <td>416</td>\n",
       "      <td>341</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp-4o-mini-p-editor</th>\n",
       "      <td>880</td>\n",
       "      <td>515</td>\n",
       "      <td>488</td>\n",
       "      <td>457</td>\n",
       "      <td>416</td>\n",
       "      <td>341</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pairwise  pairwise-P1  pairwise-P2  pairwise-P3  \\\n",
       "model                                                                     \n",
       "Total                        880          515          488          457   \n",
       "gpt-4o-mini-2024-07-18       880          515          488          457   \n",
       "lamp-4o-mini-p-editor        880          515          488          457   \n",
       "\n",
       "                        pairwise-P4  pairwise-P5  pairwise-P6  pairwise-P7  \\\n",
       "model                                                                        \n",
       "Total                           416          341          251          186   \n",
       "gpt-4o-mini-2024-07-18          416          341          251          186   \n",
       "lamp-4o-mini-p-editor           416          341          251          186   \n",
       "\n",
       "                        reward  \n",
       "model                           \n",
       "Total                     1030  \n",
       "gpt-4o-mini-2024-07-18    1030  \n",
       "lamp-4o-mini-p-editor     1030  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils_eval import compute_pairwise_metrics, extract_score\n",
    "import json, os, numpy as np, pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def evaluate_models(eval_fn):\n",
    "\n",
    "    with open(eval_fn) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    id2data = {d[\"id\"]: d for d in data}\n",
    "\n",
    "    models = set([])\n",
    "    for fn in os.listdir(\"data/preds\"):\n",
    "        with open(f\"data/preds/{fn}\") as f:\n",
    "            model_name = fn.replace(\".jsonl\", \"\").replace(\"preds_\", \"\")\n",
    "            # if \"gem-1p5\" in model_name:\n",
    "            #     continue\n",
    "            models.add(model_name)\n",
    "            for line in f:\n",
    "                d = json.loads(line)\n",
    "                if d[\"input_fn\"] != eval_fn:\n",
    "                    continue\n",
    "                id2data[d[\"id\"]][\"pred_\" + model_name] = d[\"output\"]\n",
    "\n",
    "    sample_types = {}\n",
    "    for d in data:\n",
    "        if d[\"sample_type\"] not in sample_types:\n",
    "            sample_types[d[\"sample_type\"]] = []\n",
    "        sample_types[d[\"sample_type\"]].append(d)\n",
    "\n",
    "    results, N_samples = [], []\n",
    "    total_N_samples = {\"model\": \"Total\"}\n",
    "    for sample_type in sorted(sample_types):\n",
    "        total_N_samples[sample_type] = len(sample_types[sample_type])\n",
    "    N_samples.append(total_N_samples)\n",
    "\n",
    "    # remove models that don't have any samples annotated\n",
    "    models = [model for model in models if any(\"pred_\" + model in d for d in data)]\n",
    "\n",
    "    print(models)\n",
    "\n",
    "    bad_ends = [\"-b\", \"-c\", \"-d\", \"-e\"]\n",
    "    for model in models:\n",
    "        # if any(bad_end in model for bad_end in bad_ends):\n",
    "        #     continue\n",
    "        N_samples_row = {\"model\": model}\n",
    "        result_row = {\"model\": model}\n",
    "        for sample_type in sorted(sample_types):\n",
    "            model_samples = [d for d in sample_types[sample_type] if \"pred_\" + model in d]\n",
    "            if len(model_samples) == 0:\n",
    "                continue\n",
    "            N_samples_row[sample_type] = len(model_samples)\n",
    "            if sample_type.startswith(\"pairwise\"):\n",
    "                pref1, acc, err = compute_pairwise_metrics(model_samples, model)\n",
    "                result_row[sample_type] = acc\n",
    "            else:\n",
    "                y_true = [d[\"zscore\"] for d in model_samples]\n",
    "                y_pred = []\n",
    "                for d in model_samples:\n",
    "                    pred, err = extract_score(d, \"pred_\" + model)\n",
    "                    y_pred.append(pred)\n",
    "                abs_err = np.abs(np.array(y_true) - np.array(y_pred))\n",
    "                corr = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "                avg_R = np.mean(y_pred)\n",
    "                result_row[sample_type+\"_MAE_R\"] = abs_err.mean()\n",
    "                result_row[sample_type+\"_Corr_R\"] = corr\n",
    "                result_row[sample_type+\"_Avg_R\"] = avg_R\n",
    "        N_samples.append(N_samples_row)\n",
    "\n",
    "        results.append(result_row)\n",
    "\n",
    "    # add the model eval_fn as header to the results\n",
    "    print(eval_fn.center(80, \"-\"))\n",
    "    display(pd.DataFrame(results).sort_values(by=\"pairwise\", ascending=False).set_index(\"model\").round(2))\n",
    "    display(pd.DataFrame(N_samples).set_index(\"model\").round(2))\n",
    "\n",
    "evaluate_models(eval_fn=\"data/lamp_PRGS_test.json\")\n",
    "evaluate_models(eval_fn=\"data/lamp_PR_editor_test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
