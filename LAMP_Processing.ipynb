{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create COT, Detection, and Rewriting Tuning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the three datasets.\n",
      "COT has 1000 samples.\n",
      "Detection has 1000 samples.\n",
      "Rewriting has 7234 samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# {'instruction': 'Can you recount a detailed memory of the first time you saw a sonogram of a baby, describing what you observed and felt during the experience?',\n",
    "#  'source': 'gpt4o',\n",
    "#  'type': 'Literary Fiction',\n",
    "#  'postedit': 'The soft hum of machinery filled the room with an unfamiliar yet gentle melody. I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly. The screen beside us flickered to life, a grainy black and white. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila\\'s grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room\\'s dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future.',\n",
    "#  'id': 'W18_batch2',\n",
    "#  'creativity_scores': ['5', '7'],\n",
    "#  'fine_grained_edits': [{'categorization': 'Awkward Word Choice and Phrasing',\n",
    "#    'originalText': 'The room was dimly lit, with the soft hum of machinery filling the silence',\n",
    "#    'editedText': 'The soft hum of machinery filled the room with an unfamiliar yet gentle melody.'},\n",
    "#   {'categorization': 'Lack of Specificity and Detail',\n",
    "#    'originalText': 'I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly',\n",
    "#    'editedText': 'I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly.'},\n",
    "#   {'categorization': 'Unnecessary Exposition',\n",
    "#    'originalText': \"The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal\",\n",
    "#    'editedText': 'The screen beside us flickered to life, a grainy black and white.'},\n",
    "#   {'categorization': 'Poor Sentence Structure',\n",
    "#    'originalText': \"Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth\",\n",
    "#    'editedText': \"Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth.\"},\n",
    "#   {'categorization': 'Unnecessary Exposition',\n",
    "#    'originalText': '—a future that felt both incredibly close and impossibly distant',\n",
    "#    'editedText': ''}],\n",
    "#  'data-split': 'train',\n",
    "#  'preedit': 'The room was dimly lit, with the soft hum of machinery filling the silence. I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly. The screen flickered to life, a grainy black and white, like an ancient TV trying to find it\\'s signal. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila\\'s grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room\\'s dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future—a future that felt both incredibly close and impossibly distant.',\n",
    "#  'editor': 'W18',\n",
    "#  'creativity_pre_score': 5,\n",
    "#  'creativity_post_score': 7,\n",
    "#  'creativity_z_score_pre': 3.6285013258392107,\n",
    "#  'creativity_z_score_post': 5.328722422859342,\n",
    "#  'creativity_z_score_pre_int': 4,\n",
    "#  'creativity_z_score_post_int': 5,\n",
    "#  'creativity_z_score_diff': 1,\n",
    "#  'editor_split': 'test'}\n",
    "\n",
    "with open(\"prompts/lamp_cot_input.txt\", \"r\") as f:\n",
    "    lamp_cot_input_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_cot_output.txt\", \"r\") as f:\n",
    "    lamp_cot_output_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_detection_input.txt\", \"r\") as f:\n",
    "    lamp_detection_input_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_rewriting_input.txt\", \"r\") as f:\n",
    "    lamp_rewriting_input_prompt = f.read()\n",
    "\n",
    "def prepare_cot_sample(sample):\n",
    "    input_text = lamp_cot_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"])\n",
    "\n",
    "    problematic_spans_STR = \"\"\"\"\"\"\n",
    "    for i, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        problematic_spans_STR += f\"Span {i+1}: `{edit['originalText']}` (Category: `{edit['categorization']}`)\\n\"\n",
    "\n",
    "    proposed_rewriting_STR = \"\"\"\"\"\"\n",
    "    for i, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        proposed_rewriting_STR += f\"Span {i+1}: `{edit['originalText']}` -> `{edit['editedText']}`\\n\"\n",
    "\n",
    "    output_text = lamp_cot_output_prompt.replace(\"[[PROBLEMATIC_SPANS]]\", problematic_spans_STR).replace(\"[[PROPOSED_REWRITING]]\", proposed_rewriting_STR).replace(\"[[FINAL_PARAGRAPH]]\", sample[\"postedit\"])\n",
    "    return {\"id\": sample[\"id\"], \"input_text\": input_text, \"output_text\": output_text}\n",
    "\n",
    "def prepare_detection_sample(sample):\n",
    "    input_text = lamp_detection_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"])\n",
    "    output_text = json.dumps({\"edits\": [{\"span\": edit[\"originalText\"], \"category\": edit[\"categorization\"]} for edit in sample[\"fine_grained_edits\"]]})\n",
    "    return {\"id\": sample[\"id\"], \"input_text\": input_text, \"output_text\": output_text}\n",
    "\n",
    "def prepare_rewriting_samples(sample):\n",
    "    samples = []\n",
    "    for edit_idx, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        input_text = lamp_rewriting_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"]).replace(\"[[PROBLEMATIC_SPAN]]\", edit[\"originalText\"]).replace(\"[[PROBLEMATIC_CATEGORY]]\", edit[\"categorization\"])\n",
    "        output_text = json.dumps({\"rewrite\": edit[\"editedText\"]})\n",
    "        samples.append({\"id\": f\"{sample['id']}_edit_{edit_idx}\", \"input_text\": input_text, \"output_text\": output_text})\n",
    "    return samples\n",
    "\n",
    "with open(\"data/LAMP-train-val-test.json\", \"r\") as f:\n",
    "    lamp_data = json.load(f)\n",
    "\n",
    "lamp_train = [d for d in lamp_data if d[\"data-split\"] == \"train\"]\n",
    "\n",
    "with open(\"data/lamp_train_cot_format.json\", \"w\") as f:\n",
    "    json.dump([prepare_cot_sample(sample) for sample in lamp_train], f, indent=4)\n",
    "\n",
    "with open(\"data/lamp_train_detection_format.json\", \"w\") as f:\n",
    "    json.dump([prepare_detection_sample(sample) for sample in lamp_train], f, indent=4)\n",
    "\n",
    "lamp_rewriting_samples = []\n",
    "for sample in lamp_train:\n",
    "    lamp_rewriting_samples += prepare_rewriting_samples(sample)\n",
    "\n",
    "with open(\"data/lamp_train_rewriting_format.json\", \"w\") as f:\n",
    "    json.dump(lamp_rewriting_samples, f, indent=4)\n",
    "\n",
    "print(\"Created the three datasets.\")\n",
    "print(f\"COT has {len(lamp_train)} samples.\")\n",
    "print(f\"Detection has {len(lamp_train)} samples.\")\n",
    "print(f\"Rewriting has {len(lamp_rewriting_samples)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Idenfying Problematic Spans\n",
      "\n",
      "Span 1: `The room was dimly lit, with the soft hum of machinery filling the silence` (Category: `Awkward Word Choice and Phrasing`)\n",
      "Span 2: `I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly` (Category: `Lack of Specificity and Detail`)\n",
      "Span 3: `The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal` (Category: `Unnecessary Exposition`)\n",
      "Span 4: `Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth` (Category: `Poor Sentence Structure`)\n",
      "Span 5: `—a future that felt both incredibly close and impossibly distant` (Category: `Unnecessary Exposition`)\n",
      "\n",
      "\n",
      "Part 2: Proposing Rewriting for Problematic Spans\n",
      "\n",
      "Span 1: `The room was dimly lit, with the soft hum of machinery filling the silence` -> `The soft hum of machinery filled the room with an unfamiliar yet gentle melody.`\n",
      "Span 2: `I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly` -> `I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly.`\n",
      "Span 3: `The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal` -> `The screen beside us flickered to life, a grainy black and white.`\n",
      "Span 4: `Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth` -> `Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth.`\n",
      "Span 5: `—a future that felt both incredibly close and impossibly distant` -> ``\n",
      "\n",
      "\n",
      "Part 3: Implementing Proposed Edits\n",
      "\n",
      "The soft hum of machinery filled the room with an unfamiliar yet gentle melody. I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly. The screen beside us flickered to life, a grainy black and white. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room's dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future.\n"
     ]
    }
   ],
   "source": [
    "# load cot dataset\n",
    "with open(\"data/lamp_train_cot_format.json\", \"r\") as f:\n",
    "    lamp_train_cot = json.load(f)\n",
    "\n",
    "print(lamp_train_cot[0][\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# lamp_fn = \"data/LAMP-train-val-test.json\"\n",
    "\n",
    "# with open(lamp_fn, \"r\") as f:\n",
    "#     lamp_data = json.load(f)\n",
    "# lamp_test = [d for d in lamp_data if d[\"data-split\"] == \"test\"]\n",
    "# instruction2lamp_sample = {sample['instruction']: sample for sample in lamp_test}\n",
    "\n",
    "gold_prefs = \"data/gold_preference_600.json\"\n",
    "with open(gold_prefs, \"r\") as f:\n",
    "    gold_prefs = json.load(f)\n",
    "\n",
    "eval_samples = []\n",
    "for sample_id, gold_pref in enumerate(gold_prefs):\n",
    "    sample_id = f\"gold_{sample_id}\"\n",
    "    candidates = [\n",
    "        {\"id\": f\"{sample_id}_ai_draft\", \"system\": \"ai_draft\", \"text\": gold_pref[\"AI-generated\"]},\n",
    "        {\"id\": f\"{sample_id}_human_edited\", \"system\": \"human_edited\", \"text\": gold_pref[\"Human-edited\"]},\n",
    "        {\"id\": f\"{sample_id}_fs_edited\", \"system\": \"fs_edited\", \"text\": gold_pref[\"AI-edited\"]},\n",
    "    ]\n",
    "    sample = {\"id\": sample_id, \"instruction\": gold_pref[\"instruction\"], \"candidates\": candidates}\n",
    "    eval_samples.append(sample)\n",
    "\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"w\") as f:\n",
    "    json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Additional Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_env_vars\n",
    "from utils_diff import make_colored_text\n",
    "import tqdm\n",
    "\n",
    "load_env_vars()\n",
    "\n",
    "from llms import generate, generate_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_587188/3899414031.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sample in tqdm.tqdm_notebook(todos):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a717c142ef904181a79fb7f1720f2c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_model_full_name, cot_model_short_name = \"ft:gpt-4o-2024-08-06:salesforce-research:lamp-4o-cot:Aqlv1wPq\", \"lamp-4o-cot\"\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"r\") as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "with open(\"prompts/lamp_cot_input.txt\", \"r\") as f:\n",
    "    lamp_cot_input_prompt = f.read()\n",
    "\n",
    "candidate_key = f\"edited_{cot_model_short_name}\"\n",
    "\n",
    "todos = [sample for sample in eval_samples if not any(candidate[\"system\"] == candidate_key for candidate in sample[\"candidates\"])]\n",
    "for sample in tqdm.tqdm_notebook(todos):\n",
    "    system2candidate = {candidate[\"system\"]: candidate for candidate in sample[\"candidates\"]}\n",
    "    ai_draft = system2candidate[\"ai_draft\"][\"text\"]\n",
    "\n",
    "    sample_candidate_key = f\"{sample['id']}_{candidate_key}\"\n",
    "    cot_response = generate([{\"role\": \"user\", \"content\": lamp_cot_input_prompt}], model=cot_model_full_name, variables={\"INPUT_PARAGRAPH\": ai_draft}, max_tokens=2000, step=\"lamp-editing-cot\")\n",
    "    # find the line that starts with \"Part 3\"\n",
    "    part_3_idx = cot_response.find(\"Part 3\")\n",
    "    final_rewrite = cot_response[part_3_idx:]\n",
    "\n",
    "    final_rewrite = \"\\n\".join(final_rewrite.split(\"\\n\")[1:]).strip()\n",
    "    # print(make_colored_text(ai_draft, final_rewrite))\n",
    "    sample[\"candidates\"].append({\"id\": sample_candidate_key, \"system\": candidate_key, \"text\": final_rewrite})\n",
    "\n",
    "    with open(\"data/lamp_editing_benchmark.json\", \"w\") as f:\n",
    "        json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Detect and Rewriting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_587188/1111891830.py:34: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sample in tqdm.tqdm_notebook(todos):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3921776fc447a98de2638efac07c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "detection_model, rewriting_model, system_name = \"ft:gpt-4o-2024-08-06:salesforce-research:lamp-4o-detection:Aqna3sJ6\", \"ft:gpt-4o-2024-08-06:salesforce-research:lamp-4o-rewriting:AqpAqwih\", \"lamp-4o-dnr\"\n",
    "\n",
    "with open(\"prompts/lamp_detection_input.txt\", \"r\") as f:\n",
    "    lamp_detection_input_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_rewriting_input.txt\", \"r\") as f:\n",
    "    lamp_rewriting_input_prompt = f.read()\n",
    "\n",
    "def run_dnr_pipeline(ai_draft, detection_model, rewriting_model):\n",
    "    # 1. Detect\n",
    "    detection_response = generate_json([{\"role\": \"user\", \"content\": lamp_detection_input_prompt}], model=detection_model, variables={\"INPUT_PARAGRAPH\": ai_draft}, step=\"lamp-editing-dnr-detection\")\n",
    "\n",
    "    edits = detection_response[\"edits\"]\n",
    "    filtered_edits = [edit for edit in edits if edit[\"span\"] in ai_draft and ai_draft.count(edit[\"span\"]) == 1]\n",
    "\n",
    "    # 2. Rewrite\n",
    "    for edit in filtered_edits:\n",
    "        output_rewrite = generate_json([{\"role\": \"user\", \"content\": lamp_rewriting_input_prompt}], model=rewriting_model, variables={\"INPUT_PARAGRAPH\": ai_draft, \"PROBLEMATIC_SPAN\": edit[\"span\"], \"PROBLEMATIC_CATEGORY\": edit[\"category\"]}, step=\"lamp-editing-dnr\")\n",
    "        edit[\"rewrite\"] = output_rewrite[\"rewrite\"]\n",
    "\n",
    "    # 3. Apply te edits\n",
    "    edited_text = ai_draft\n",
    "    for edit in filtered_edits:\n",
    "        edited_text = edited_text.replace(edit[\"span\"], edit[\"rewrite\"])\n",
    "\n",
    "    return edited_text, filtered_edits\n",
    "\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"r\") as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "todos = [sample for sample in eval_samples if not any(candidate[\"system\"] == system_name for candidate in sample[\"candidates\"])]\n",
    "\n",
    "for sample in tqdm.tqdm_notebook(todos):\n",
    "    system2candidate = {candidate[\"system\"]: candidate for candidate in sample[\"candidates\"]}\n",
    "    ai_draft = system2candidate[\"ai_draft\"][\"text\"]\n",
    "\n",
    "    sample_candidate_key = f\"{sample['id']}_{system_name}\"\n",
    "    edited_text, edits = run_dnr_pipeline(ai_draft, detection_model, rewriting_model)\n",
    "    sample[\"candidates\"].append({\"id\": sample_candidate_key, \"system\": system_name, \"text\": edited_text, \"edits\": edits})\n",
    "\n",
    "    with open(\"data/lamp_editing_benchmark.json\", \"w\") as f:\n",
    "        json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Reward-based Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_587188/2821915331.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, todo in enumerate(tqdm.tqdm_notebook(todos)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479eb71a580a44328c2f99910d2983cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_70_lamp-4o-dnr 6\n",
      "gold_70_edited_lamp-4o-cot 7\n",
      "gold_71_lamp-4o-dnr 5\n",
      "gold_71_edited_lamp-4o-cot 6\n",
      "gold_72_lamp-4o-dnr 6\n",
      "gold_72_edited_lamp-4o-cot 6\n",
      "gold_73_edited_lamp-4o-cot 6\n",
      "gold_73_lamp-4o-dnr 7\n",
      "gold_74_edited_lamp-4o-cot 7\n",
      "gold_74_lamp-4o-dnr 7\n",
      "gold_75_edited_lamp-4o-cot 6\n",
      "gold_75_lamp-4o-dnr 7\n",
      "gold_76_edited_lamp-4o-cot 6\n",
      "gold_76_lamp-4o-dnr 6\n",
      "gold_77_edited_lamp-4o-cot 7\n",
      "gold_77_lamp-4o-dnr 6\n",
      "gold_78_edited_lamp-4o-cot 8\n",
      "gold_78_lamp-4o-dnr 5\n",
      "gold_79_edited_lamp-4o-cot 7\n",
      "gold_79_lamp-4o-dnr 7\n",
      "gold_80_edited_lamp-4o-cot 5\n",
      "gold_80_lamp-4o-dnr 4\n",
      "gold_81_edited_lamp-4o-cot 5\n",
      "gold_81_lamp-4o-dnr 6\n",
      "gold_82_edited_lamp-4o-cot 7\n",
      "gold_82_lamp-4o-dnr 6\n",
      "gold_83_edited_lamp-4o-cot 6\n",
      "gold_83_lamp-4o-dnr 6\n",
      "gold_84_ai_draft 3\n",
      "gold_84_human_edited 6\n",
      "gold_84_fs_edited 5\n",
      "gold_84_edited_lamp-4o-cot 5\n",
      "gold_84_lamp-4o-dnr 4\n",
      "gold_85_ai_draft 6\n",
      "gold_85_human_edited 8\n",
      "gold_85_fs_edited 9\n",
      "gold_85_edited_lamp-4o-cot 8\n",
      "gold_85_lamp-4o-dnr 7\n",
      "gold_86_ai_draft 7\n",
      "gold_86_human_edited 8\n",
      "gold_86_fs_edited 7\n",
      "gold_86_edited_lamp-4o-cot 7\n",
      "gold_86_lamp-4o-dnr 8\n",
      "gold_87_ai_draft 6\n",
      "gold_87_human_edited 8\n",
      "gold_87_fs_edited 5\n",
      "gold_87_edited_lamp-4o-cot 6\n",
      "gold_87_lamp-4o-dnr 6\n",
      "gold_88_ai_draft 6\n",
      "gold_88_human_edited 8\n",
      "gold_88_fs_edited 7\n",
      "gold_88_edited_lamp-4o-cot 7\n",
      "gold_88_lamp-4o-dnr 7\n",
      "gold_89_ai_draft 7\n",
      "gold_89_human_edited 6\n",
      "gold_89_fs_edited 7\n",
      "gold_89_edited_lamp-4o-cot 8\n",
      "gold_89_lamp-4o-dnr 6\n",
      "gold_90_ai_draft 6\n"
     ]
    }
   ],
   "source": [
    "from utils import load_env_vars\n",
    "\n",
    "load_env_vars()\n",
    "\n",
    "from llms import generate_json\n",
    "import tqdm, json\n",
    "\n",
    "with open(\"prompts/reward_calc.txt\", \"r\") as f:\n",
    "    reward_calc_prompt = f.read()\n",
    "\n",
    "REWARD_MODEL = \"ft:gpt-4o-2024-08-06:salesforce-research:lamp-4o-p:AYKM53Ac\"\n",
    "\n",
    "def calculate_reward(candidate):\n",
    "    output_response = generate_json([{\"role\": \"user\", \"content\": reward_calc_prompt}], model=REWARD_MODEL, variables={\"PARAGRAPH\": candidate[\"text\"]}, step=\"lamp-editing-r-eval\")\n",
    "    candidate[\"score\"] = output_response[\"score\"]\n",
    "    print(candidate[\"id\"], candidate[\"score\"])\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"r\") as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "todos = [candidate for sample in eval_samples for candidate in sample[\"candidates\"] if \"score\" not in candidate]\n",
    "for i, todo in enumerate(tqdm.tqdm_notebook(todos)):\n",
    "    calculate_reward(todo)\n",
    "\n",
    "    if i%10 == 0 or i == len(todos)-1:\n",
    "        with open(\"data/lamp_editing_benchmark.json\", \"w\") as f:\n",
    "            json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>N</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human_edited</td>\n",
       "      <td>84</td>\n",
       "      <td>6.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edited_lamp-4o-cot</td>\n",
       "      <td>69</td>\n",
       "      <td>6.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamp-4o-dnr</td>\n",
       "      <td>70</td>\n",
       "      <td>6.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fs_edited</td>\n",
       "      <td>84</td>\n",
       "      <td>5.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai_draft</td>\n",
       "      <td>84</td>\n",
       "      <td>5.619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               system   N  score\n",
       "1        human_edited  84  6.964\n",
       "3  edited_lamp-4o-cot  69  6.362\n",
       "4         lamp-4o-dnr  70  6.186\n",
       "2           fs_edited  84  5.929\n",
       "0            ai_draft  84  5.619"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"r\") as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "candidates_scored = [candidate for sample in eval_samples for candidate in sample[\"candidates\"] if \"score\" in candidate]\n",
    "\n",
    "system_scores = defaultdict(list)\n",
    "for candidate in candidates_scored:\n",
    "    system_scores[candidate[\"system\"]].append(candidate[\"score\"])\n",
    "\n",
    "results = [{\"system\": system, \"N\": len(scores), \"score\": np.mean(scores)} for system, scores in system_scores.items()]\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=\"score\", ascending=False).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
