{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the three datasets.\n",
      "COT has 1000 samples.\n",
      "Detection has 1000 samples.\n",
      "Rewriting has 7234 samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# {'instruction': 'Can you recount a detailed memory of the first time you saw a sonogram of a baby, describing what you observed and felt during the experience?',\n",
    "#  'source': 'gpt4o',\n",
    "#  'type': 'Literary Fiction',\n",
    "#  'postedit': 'The soft hum of machinery filled the room with an unfamiliar yet gentle melody. I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly. The screen beside us flickered to life, a grainy black and white. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila\\'s grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room\\'s dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future.',\n",
    "#  'id': 'W18_batch2',\n",
    "#  'creativity_scores': ['5', '7'],\n",
    "#  'fine_grained_edits': [{'categorization': 'Awkward Word Choice and Phrasing',\n",
    "#    'originalText': 'The room was dimly lit, with the soft hum of machinery filling the silence',\n",
    "#    'editedText': 'The soft hum of machinery filled the room with an unfamiliar yet gentle melody.'},\n",
    "#   {'categorization': 'Lack of Specificity and Detail',\n",
    "#    'originalText': 'I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly',\n",
    "#    'editedText': 'I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly.'},\n",
    "#   {'categorization': 'Unnecessary Exposition',\n",
    "#    'originalText': \"The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal\",\n",
    "#    'editedText': 'The screen beside us flickered to life, a grainy black and white.'},\n",
    "#   {'categorization': 'Poor Sentence Structure',\n",
    "#    'originalText': \"Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth\",\n",
    "#    'editedText': \"Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth.\"},\n",
    "#   {'categorization': 'Unnecessary Exposition',\n",
    "#    'originalText': '—a future that felt both incredibly close and impossibly distant',\n",
    "#    'editedText': ''}],\n",
    "#  'data-split': 'train',\n",
    "#  'preedit': 'The room was dimly lit, with the soft hum of machinery filling the silence. I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly. The screen flickered to life, a grainy black and white, like an ancient TV trying to find it\\'s signal. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila\\'s grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room\\'s dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future—a future that felt both incredibly close and impossibly distant.',\n",
    "#  'editor': 'W18',\n",
    "#  'creativity_pre_score': 5,\n",
    "#  'creativity_post_score': 7,\n",
    "#  'creativity_z_score_pre': 3.6285013258392107,\n",
    "#  'creativity_z_score_post': 5.328722422859342,\n",
    "#  'creativity_z_score_pre_int': 4,\n",
    "#  'creativity_z_score_post_int': 5,\n",
    "#  'creativity_z_score_diff': 1,\n",
    "#  'editor_split': 'test'}\n",
    "\n",
    "with open(\"prompts/lamp_cot_input.txt\", \"r\") as f:\n",
    "    lamp_cot_input_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_cot_output.txt\", \"r\") as f:\n",
    "    lamp_cot_output_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_detection_input.txt\", \"r\") as f:\n",
    "    lamp_detection_input_prompt = f.read()\n",
    "\n",
    "with open(\"prompts/lamp_rewriting_input.txt\", \"r\") as f:\n",
    "    lamp_rewriting_input_prompt = f.read()\n",
    "\n",
    "def prepare_cot_sample(sample):\n",
    "    input_text = lamp_cot_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"])\n",
    "\n",
    "    problematic_spans_STR = \"\"\"\"\"\"\n",
    "    for i, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        problematic_spans_STR += f\"Span {i+1}: `{edit['originalText']}` (Category: `{edit['categorization']}`)\\n\"\n",
    "\n",
    "    proposed_rewriting_STR = \"\"\"\"\"\"\n",
    "    for i, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        proposed_rewriting_STR += f\"Span {i+1}: `{edit['originalText']}` -> `{edit['editedText']}`\\n\"\n",
    "\n",
    "    output_text = lamp_cot_output_prompt.replace(\"[[PROBLEMATIC_SPANS]]\", problematic_spans_STR).replace(\"[[PROPOSED_REWRITING]]\", proposed_rewriting_STR).replace(\"[[FINAL_PARAGRAPH]]\", sample[\"postedit\"])\n",
    "    return {\"id\": sample[\"id\"], \"input_text\": input_text, \"output_text\": output_text}\n",
    "\n",
    "def prepare_detection_sample(sample):\n",
    "    input_text = lamp_detection_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"])\n",
    "    output_text = json.dumps({\"edits\": [{\"span\": edit[\"originalText\"], \"category\": edit[\"categorization\"]} for edit in sample[\"fine_grained_edits\"]]})\n",
    "    return {\"id\": sample[\"id\"], \"input_text\": input_text, \"output_text\": output_text}\n",
    "\n",
    "def prepare_rewriting_samples(sample):\n",
    "    samples = []\n",
    "    for edit_idx, edit in enumerate(sample[\"fine_grained_edits\"]):\n",
    "        input_text = lamp_rewriting_input_prompt.replace(\"[[INPUT_PARAGRAPH]]\", sample[\"preedit\"]).replace(\"[[PROBLEMATIC_SPAN]]\", edit[\"originalText\"]).replace(\"[[PROBLEMATIC_CATEGORY]]\", edit[\"categorization\"])\n",
    "        output_text = json.dumps({\"rewrite\": edit[\"editedText\"]})\n",
    "        samples.append({\"id\": f\"{sample['id']}_edit_{edit_idx}\", \"input_text\": input_text, \"output_text\": output_text})\n",
    "    return samples\n",
    "\n",
    "with open(\"data/LAMP-train-val-test.json\", \"r\") as f:\n",
    "    lamp_data = json.load(f)\n",
    "\n",
    "lamp_train = [d for d in lamp_data if d[\"data-split\"] == \"train\"]\n",
    "\n",
    "with open(\"data/lamp_train_cot_format.json\", \"w\") as f:\n",
    "    json.dump([prepare_cot_sample(sample) for sample in lamp_train], f, indent=4)\n",
    "\n",
    "with open(\"data/lamp_train_detection_format.json\", \"w\") as f:\n",
    "    json.dump([prepare_detection_sample(sample) for sample in lamp_train], f, indent=4)\n",
    "\n",
    "lamp_rewriting_samples = []\n",
    "for sample in lamp_train:\n",
    "    lamp_rewriting_samples += prepare_rewriting_samples(sample)\n",
    "\n",
    "with open(\"data/lamp_train_rewriting_format.json\", \"w\") as f:\n",
    "    json.dump(lamp_rewriting_samples, f, indent=4)\n",
    "\n",
    "print(\"Created the three datasets.\")\n",
    "print(f\"COT has {len(lamp_train)} samples.\")\n",
    "print(f\"Detection has {len(lamp_train)} samples.\")\n",
    "print(f\"Rewriting has {len(lamp_rewriting_samples)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Idenfying Problematic Spans\n",
      "\n",
      "Span 1: `The room was dimly lit, with the soft hum of machinery filling the silence` (Category: `Awkward Word Choice and Phrasing`)\n",
      "Span 2: `I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly` (Category: `Lack of Specificity and Detail`)\n",
      "Span 3: `The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal` (Category: `Unnecessary Exposition`)\n",
      "Span 4: `Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth` (Category: `Poor Sentence Structure`)\n",
      "Span 5: `—a future that felt both incredibly close and impossibly distant` (Category: `Unnecessary Exposition`)\n",
      "\n",
      "\n",
      "Part 2: Proposing Rewriting for Problematic Spans\n",
      "\n",
      "Span 1: `The room was dimly lit, with the soft hum of machinery filling the silence` -> `The soft hum of machinery filled the room with an unfamiliar yet gentle melody.`\n",
      "Span 2: `I sat beside Lila, squeezing her hand, as the technician swirled the wand over her belly` -> `I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly.`\n",
      "Span 3: `The screen flickered to life, a grainy black and white, like an ancient TV trying to find it's signal` -> `The screen beside us flickered to life, a grainy black and white.`\n",
      "Span 4: `Lila's grip tightened, and I glanced at her, finding her eyes glossy, a smile tugging at the corners of her mouth` -> `Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth.`\n",
      "Span 5: `—a future that felt both incredibly close and impossibly distant` -> ``\n",
      "\n",
      "\n",
      "Part 3: Implementing Proposed Edits\n",
      "\n",
      "The soft hum of machinery filled the room with an unfamiliar yet gentle melody. I sat beside Lila, squeezing her hand as she lay on the table while the technician swirled the wand over her rounded belly. The screen beside us flickered to life, a grainy black and white. Slowly, an image began to form; the unmistakable curve of a tiny head, the flutter of something I later learned was a heartbeat. I leaned forward, almost holding my breath, mesmerized by the play of light and shadows that composed this new life. Lila's grip tightened and upon glancing at her, I found her eyes glossy, along with a smile tugging at the corners of her mouth. I turned back to the screen, emotions swirling—awe, fear, hope. In that moment, the abstract idea of \"our baby\" transformed into something real, tangible. The room's dimness seemed to fold around us, making space for this silent, wordless connection. There, in the ghostly shapes on the monitor, I saw not just a child, but a future.\n"
     ]
    }
   ],
   "source": [
    "# load cot dataset\n",
    "with open(\"data/lamp_train_cot_format.json\", \"r\") as f:\n",
    "    lamp_train_cot = json.load(f)\n",
    "\n",
    "print(lamp_train_cot[0][\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# lamp_fn = \"data/LAMP-train-val-test.json\"\n",
    "\n",
    "# with open(lamp_fn, \"r\") as f:\n",
    "#     lamp_data = json.load(f)\n",
    "# lamp_test = [d for d in lamp_data if d[\"data-split\"] == \"test\"]\n",
    "# instruction2lamp_sample = {sample['instruction']: sample for sample in lamp_test}\n",
    "\n",
    "gold_prefs = \"data/gold_preference_600.json\"\n",
    "with open(gold_prefs, \"r\") as f:\n",
    "    gold_prefs = json.load(f)\n",
    "\n",
    "eval_samples = []\n",
    "for sample_id, gold_pref in enumerate(gold_prefs):\n",
    "    sample_id = f\"gold_{sample_id}\"\n",
    "    candidates = [\n",
    "        {\"id\": f\"{sample_id}_ai_draft\", \"system\": \"ai_draft\", \"text\": gold_pref[\"AI-generated\"]},\n",
    "        {\"id\": f\"{sample_id}_human_edited\", \"system\": \"human_edited\", \"text\": gold_pref[\"Human-edited\"]},\n",
    "        {\"id\": f\"{sample_id}_fs_edited\", \"system\": \"fs_edited\", \"text\": gold_pref[\"AI-edited\"]},\n",
    "    ]\n",
    "    sample = {\"id\": sample_id, \"instruction\": gold_pref[\"instruction\"], \"candidates\": candidates}\n",
    "    eval_samples.append(sample)\n",
    "\n",
    "\n",
    "len(eval_samples)\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"w\") as f:\n",
    "    json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n"
     ]
    }
   ],
   "source": [
    "from llms import generate_json\n",
    "import tqdm\n",
    "\n",
    "with open(\"prompts/reward_calc.txt\", \"r\") as f:\n",
    "    reward_calc_prompt = f.read()\n",
    "\n",
    "REWARD_MODEL = \"gpt-4o\"\n",
    "\n",
    "def calculate_reward(candidate):\n",
    "    input_text = reward_calc_prompt.replace(\"[[PARAGRAPH]]\", candidate[\"text\"])\n",
    "    output_response = generate_json([{\"role\": \"user\", \"content\": reward_calc_prompt}], model=REWARD_MODEL, variables={\"PARAGRAPH\": candidate[\"text\"]})\n",
    "    candidate[\"score\"] = output_response[\"score\"]\n",
    "\n",
    "with open(\"data/lamp_editing_benchmark.json\", \"r\") as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "todos = [candidate for sample in eval_samples for candidate in sample[\"candidates\"]]\n",
    "for i, todo in tqdm.tqdm(enumerate(todos)):\n",
    "    # calculate_reward(todo)\n",
    "\n",
    "    if i%10 == 0 or i == len(todos)-1:\n",
    "        with open(\"data/lamp_editing_benchmark_with_scores.json\", \"w\") as f:\n",
    "            json.dump(eval_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
